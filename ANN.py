# ------------------------------------------------------EXPLANATION-----------------------------------------------------
# DESCRIPTION:
# Takes in a state and produces a probability distribution over actions.

# INPUT:
# A state
# -------------------------------------------------------IMPORTS--------------------------------------------------------
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import numpy as np
# --------------------------------------------------------LOGIC---------------------------------------------------------

class ANN:
    def __init__(self, lr, input_layer, hidden_layers, output_layer):
        self.lr = lr #learning rate
        self.input_layer  = input_layer
        self.hidden_layers = hidden_layers
        self.output_layer = output_layer

        self.model = self.generate_NN()

    def generate_NN(self):
        model = Sequential()
        model.add(Dense(self.input_layer, activation='relu', input_dim=self.input_layer)) #input layer, activation relu: just positive numbers as weights and output
        for layer in self.hidden_layers:
            model.add(Dense(layer, activation='relu')) #hidden layers
        model.add(Dense(self.output_layer)) # output is a probability distribution over states
        optimizer = tf.optimizers.Adagrad(learning_rate=self.lr)
        model.compile(optimizer=optimizer, loss=tf.keras.losses.MeanSquaredError(), run_eagerly = True) #hyper parameters which are subject to changes, fine tuning
        return model

    # The results from the MCTS is used to train our Actor Neural Network.
    # By normalizing children visit counts you get a probability distribution which can be used to train the NN
    # Target: probability distribution generated by MCTS
    def fit(self):
        return
    
    # the error is the difference between the probability distribution generatated by MCTS and by ANN
    # Use a loss function like cross entropy
    def get_error(self):
        return

    # get probability distribution over all possible actions from state
    def get_action_probabilities(self, state):
        return self.model(get_tensor(state))

# ------------------------------------------------------ STATIC METHODS-------------------------------------------------
def get_tensor(state):
    state = [tf.strings.to_number(bin, out_type=tf.dtypes.int32) for bin in state] # convert to array
    state = tf.convert_to_tensor(np.expand_dims(state, axis=0))
    return state